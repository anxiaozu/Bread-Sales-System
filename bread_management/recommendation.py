import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors
from django.db.models import Count
import logging
from bread_management.models import Bread
from user_management.models import Profile

# ç”¨æˆ·åå¥½ä¸­å¯èƒ½çš„å‰ç¼€
PREFERENCE_PREFIXES = ["å–œæ¬¢åƒ", "æœ€çˆ±", "å¸¸åƒ", "è®¨åŒ", "ä¸å–œæ¬¢", "æ¨è", "å°è¯•"]


def clean_preference(pref):
    """ å»æ‰ç”¨æˆ·åå¥½ä¸­çš„å‰ç¼€ï¼Œæå–å…³é”®å­— """
    for prefix in PREFERENCE_PREFIXES:
        if pref.startswith(prefix):
            pref = pref[len(prefix):]
            break
    return pref.strip()


def build_bread_feature_matrix():
    """
    æ„é€ æ‰€æœ‰é¢åŒ…çš„ç‰¹å¾çŸ©é˜µã€‚
    å¯¹æ¯ä¸ªé¢åŒ…ï¼Œå°†åç§°å’Œæè¿°æ‹¼æ¥èµ·æ¥ï¼Œåˆ©ç”¨ TfidfVectorizer è½¬æ¢ä¸ºå‘é‡ï¼ˆ15 ç»´ï¼‰ï¼Œ
    ç„¶ååœ¨å‰é¢æ·»åŠ ä¸€åˆ—å¹´é¾„å ä½ç¬¦ï¼ˆå¡« 0ï¼‰ï¼Œä½¿å¾—æ€»ç‰¹å¾ç»´åº¦ä¸º 16ã€‚
    """
    bread_list = list(Bread.objects.all())
    # æ‹¼æ¥é¢åŒ…åç§°å’Œæè¿°
    bread_texts = [f"{bread.name} {bread.description}" for bread in bread_list]
    vectorizer = TfidfVectorizer(max_features=15)
    tfidf_matrix = vectorizer.fit_transform(bread_texts).toarray()  # shape: (n_bread, 15)
    # ä¸ºæ¯ä¸ªé¢åŒ…å¢åŠ ä¸€åˆ—å¹´é¾„å ä½ç¬¦ï¼ˆé¢åŒ…æ²¡æœ‰å¹´é¾„ï¼Œç»Ÿä¸€å¡« 0ï¼‰
    age_placeholder = np.zeros((tfidf_matrix.shape[0], 1))
    bread_features = np.concatenate((age_placeholder, tfidf_matrix), axis=1)  # shape: (n_bread, 16)
    return bread_list, bread_features, vectorizer


def build_user_feature(user_preferences, user_age, vectorizer):
    """
    æ„é€ ç”¨æˆ·ç‰¹å¾å‘é‡ï¼š
    - å°†ç”¨æˆ·åå¥½ï¼ˆæ¸…æ´—åæ‹¼æ¥çš„æ–‡æœ¬ï¼‰è½¬æ¢ä¸º TF-IDF å‘é‡ï¼ˆ15 ç»´ï¼‰ï¼Œ
    - å°†ç”¨æˆ·å¹´é¾„å½’ä¸€åŒ–ï¼ˆé™¤ä»¥ 100ï¼‰ï¼Œå¾—åˆ° 1 ç»´ç‰¹å¾ï¼Œ
    - æœ€åæ‹¼æ¥æˆ 16 ç»´å‘é‡ã€‚
    """
    cleaned_prefs = [clean_preference(p) for p in user_preferences]
    pref_text = " ".join(cleaned_prefs)
    user_tfidf = vectorizer.transform([pref_text]).toarray()  # shape: (1, 15)
    normalized_age = np.array([[user_age / 100.0]])  # shape: (1, 1)
    user_feature = np.concatenate((normalized_age, user_tfidf), axis=1)  # shape: (1, 16)
    return user_feature


def recommend_bread_knn(user_id, k=3):
    """
    åˆ©ç”¨ KNN è¿›è¡Œé¢åŒ…æ¨èï¼š
    1. æ„é€ é¢åŒ…ç‰¹å¾çŸ©é˜µï¼ˆåŒ…æ‹¬åç§°å’Œæè¿°çš„ TF-IDF ä»¥åŠå¹´é¾„å ä½ç¬¦ï¼‰
    2. æ„é€ å½“å‰ç”¨æˆ·ç‰¹å¾å‘é‡ï¼ˆåŸºäºç”¨æˆ·åå¥½å’Œå½’ä¸€åŒ–å¹´é¾„ï¼‰
    3. åˆ©ç”¨ NearestNeighborsï¼ˆä½™å¼¦è·ç¦»ï¼‰æ‰¾å‡ºä¸ç”¨æˆ·ç‰¹å¾æœ€æ¥è¿‘çš„ k ä¸ªé¢åŒ…
    4. å¦‚æœæ²¡æœ‰æ¨èç»“æœï¼Œåˆ™è¿”å›é”€é‡æœ€é«˜çš„é¢åŒ…
    """
    try:
        profile = Profile.objects.get(user_id=user_id)
        user_age = profile.age if profile.age is not None else 30
        user_preferences = profile.preferences.split(',') if profile.preferences else []

        # æ„é€ é¢åŒ…ç‰¹å¾çŸ©é˜µ
        bread_list, bread_features, vectorizer = build_bread_feature_matrix()
        if len(bread_list) == 0:
            return Bread.objects.annotate(sales_count=Count('order')).order_by('-sales_count')[:k]

        # æ„é€ å½“å‰ç”¨æˆ·ç‰¹å¾å‘é‡ï¼ˆ16 ç»´ï¼‰
        user_feature = build_user_feature(user_preferences, user_age, vectorizer)

        # ä½¿ç”¨ KNN è®¡ç®—ä½™å¼¦è·ç¦»
        nbrs = NearestNeighbors(n_neighbors=k, metric='cosine').fit(bread_features)
        distances, indices = nbrs.kneighbors(user_feature)

        # ç¡®ä¿ç´¢å¼•ä¸º Python int ç±»å‹ï¼Œå¹¶è¿‡æ»¤æ‰è¶…å‡ºèŒƒå›´çš„ç´¢å¼•
        indices = [int(i) for i in indices[0] if int(i) < len(bread_list)]
        recommended_breads = [bread_list[i] for i in indices]

        # å¦‚æœæ¨èä¸ºç©ºï¼Œåˆ™æŒ‰é”€é‡æœ€é«˜è¿”å›
        if not recommended_breads:
            recommended_breads = Bread.objects.annotate(sales_count=Count('order')).order_by('-sales_count')[:k]

        return recommended_breads

    except Exception as e:
        logging.error(f"ğŸš¨ æ¨èå‡½æ•°å¼‚å¸¸: {str(e)}")
        return Bread.objects.annotate(sales_count=Count('order')).order_by('-sales_count')[:k]

import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from django.db.models import Count
import logging
from bread_management.models import Bread
from user_management.models import Profile
def preprocess_data(user_ages, user_preferences, bread_categories, bread_descriptions):
    """ æ•°æ®é¢„å¤„ç† """
    scaler = StandardScaler()
    ages_normalized = scaler.fit_transform(np.array(user_ages).reshape(-1, 1))

    encoder = OneHotEncoder(handle_unknown="ignore")
    encoder.fit(np.array(bread_categories).reshape(-1, 1))
    preferences_encoded = np.array([
        encoder.transform(np.array(pref).reshape(-1, 1)).toarray().sum(axis=0) if pref else np.zeros(len(bread_categories))
        for pref in user_preferences
    ])

    vectorizer = TfidfVectorizer(max_features=50)
    bread_descriptions_encoded = vectorizer.fit_transform(bread_descriptions).toarray()

    # **æ•°æ®å¢å¼ºï¼šå¤åˆ¶å°‘æ•°ç±»åˆ«çš„æ•°æ®**
    max_length = max(len(ages_normalized), len(preferences_encoded), len(bread_descriptions_encoded))
    ages_normalized = np.resize(ages_normalized, (max_length, ages_normalized.shape[1]))
    preferences_encoded = np.resize(preferences_encoded, (max_length, preferences_encoded.shape[1]))
    bread_descriptions_encoded = np.resize(bread_descriptions_encoded, (max_length, bread_descriptions_encoded.shape[1]))

    return ages_normalized, preferences_encoded, bread_descriptions_encoded, encoder, vectorizer

def build_dnn_model(input_dim, output_dim):
    """ æ„å»ºç¥ç»ç½‘ç»œæ¨¡å‹ """
    model = Sequential([
        Dense(128, input_dim=input_dim, activation='relu'),
        Dropout(0.2),
        Dense(64, activation='relu'),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dense(output_dim, activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])
    return model

def train_model(model, X, y):
    """ è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹ """
    y_unique = np.unique(y.argmax(axis=1))
    if len(y_unique) < y.shape[1]:
        missing_classes = set(range(y.shape[1])) - set(y_unique)
        print(f"âš ï¸ è®­ç»ƒæ•°æ®ç¼ºå°‘ç±»åˆ« {missing_classes}ï¼Œè¡¥å……æ•°æ®")
        for cls in missing_classes:
            y = np.vstack([y, np.eye(y.shape[1])[cls]])
            X = np.vstack([X, np.zeros((1, X.shape[1]))])

    model.fit(X, y, epochs=50, batch_size=16, verbose=1)
    return model

def recommend_bread_dnn(user_id):
    try:
        profile = Profile.objects.get(user_id=user_id)
        age = profile.age if profile.age is not None else 30
        preferences = profile.preferences.split(',') if profile.preferences else []

        all_profiles = Profile.objects.all()
        user_ages = [p.age if p.age is not None else 30 for p in all_profiles]
        user_preferences = [p.preferences.split(',') if p.preferences else [] for p in all_profiles]
        bread_list = Bread.objects.all()

        bread_categories = list(set(cat.name for bread in bread_list for cat in bread.categories.all()))
        bread_descriptions = [bread.description if bread.description else "" for bread in bread_list]

        # **é¢„å¤„ç†æ•°æ®**
        ages_normalized, preferences_encoded, bread_descriptions_encoded, encoder, vectorizer = preprocess_data(
            user_ages, user_preferences, bread_categories, bread_descriptions
        )

        input_dim = ages_normalized.shape[1] + preferences_encoded.shape[1] + bread_descriptions_encoded.shape[1]
        output_dim = len(bread_categories)

        # **ä¿®æ­£ `y` ç›®æ ‡ç±»åˆ«**
        y = np.array([
            encoder.transform(np.array(pref).reshape(-1, 1)).toarray().sum(axis=0) if pref else
            np.eye(len(bread_categories))[np.random.randint(0, len(bread_categories))]
            for pref in user_preferences
        ])

        model = build_dnn_model(input_dim, output_dim)
        X = np.concatenate((ages_normalized, preferences_encoded, bread_descriptions_encoded), axis=1)
        model = train_model(model, X, y)

        # **TF-IDF è®¡ç®— `ç”¨æˆ·åå¥½` ä¸ `é¢åŒ…æè¿°` çš„ç›¸ä¼¼åº¦**
        user_pref_vector = vectorizer.transform([" ".join(preferences)]).toarray()
        similarity_scores = cosine_similarity(user_pref_vector, bread_descriptions_encoded)

        # **å–ç›¸ä¼¼åº¦æœ€é«˜çš„ 3 ä¸ªé¢åŒ…**
        top_indices = similarity_scores.argsort()[0][-3:][::-1]
        top_indices = [i for i in top_indices if i < len(bread_list)]
        recommended_breads = [bread_list[int(i)] for i in top_indices]  # âœ… è½¬æ¢ä¸º Python `int`

        if not recommended_breads:
            print("æŒ‰ç…§é”€é‡æ¨è")
            recommended_breads = Bread.objects.annotate(sales_count=Count('order')).order_by('-sales_count')[:3]

        # **è®¡ç®—å‡†ç¡®ç‡**
        correct_predictions = sum(1 for bread in recommended_breads if any(pref.lower() in bread.description.lower() for pref in preferences))
        accuracy = correct_predictions / len(recommended_breads) if recommended_breads else 0
        print(f"ğŸ¯ é¢„æµ‹å‡†ç¡®ç‡: {accuracy * 100:.2f}%")

        return recommended_breads

    except Exception as e:
        logging.error(f"ğŸš¨ æ¨èå‡½æ•°å¼‚å¸¸: {str(e)}")
        return Bread.objects.annotate(sales_count=Count('order')).order_by('-sales_count')[:3]
